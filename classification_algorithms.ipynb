{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfLl0azvAONFlNViMdFJuM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diogoferraz/ai-mba/blob/main/classification_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependency"
      ],
      "metadata": {
        "id": "3m17XVPrCU_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U ucimlrepo"
      ],
      "metadata": {
        "id": "1lllfHB2CUbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libs"
      ],
      "metadata": {
        "id": "SBHVCu86CSRh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca5rpKlEtFip"
      },
      "outputs": [],
      "source": [
        "# Vamos começar, importando a função filterwarnings da biblioteca\n",
        "# warnings. Vamos desabilitar os warnigs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Em seguida, vamos importar as funções necessárias para rodarmos\n",
        "# os algoritmos de machine learning para os problemas de classificação.\n",
        "\n",
        "import pandas as pd   # importando a biblioteca Pandas\n",
        "import numpy as np    # importando a biblioteca NumPy\n",
        "import matplotlib.pyplot as plt  # importando a biblioteca Matplotlib\n",
        "from matplotlib import cm\n",
        "from sklearn.model_selection import train_test_split # função que executa o split em bases de treino e teste (holdout)\n",
        "from sklearn.model_selection import KFold # função que faz as divisões dos subgrupos para a validação cruzada\n",
        "from sklearn.model_selection import cross_val_score # função que executa a validação cruzada\n",
        "from sklearn.metrics import accuracy_score # função que faz a exibição da acurácia do modelo\n",
        "from sklearn.neighbors import KNeighborsClassifier # implementa algoritmo KNN para a classificação\n",
        "from sklearn.tree import DecisionTreeClassifier # implementa o algoritmo Árvore de Classificação\n",
        "from sklearn.naive_bayes import GaussianNB # implementa o algoritmo Naive Bayes\n",
        "from sklearn.svm import SVC # implementa o algoritmo SVM\n",
        "from sklearn.linear_model import LogisticRegression # implementa o algoritmo de Regressão logística\n",
        "from ucimlrepo import fetch_ucirepo # import Iris dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga do dataset (classificação)"
      ],
      "metadata": {
        "id": "RQFTNbvsB5tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga do dataset\n",
        "#iris = load_iris()\n",
        "#dataset = pd.DataFrame(iris.data, columns=iris.feature_names) # conversão para dataframe\n",
        "#dataset['target'] = iris.class # adição da coluna target\n",
        "\n",
        "#dataset.head()\n",
        "\n",
        "# buscando o  dataset\n",
        "iris_ = fetch_ucirepo(id=53)\n",
        "\n",
        "# dados (como dataframes do Pandas)\n",
        "X = iris_.data.features\n",
        "y = iris_.data.targets\n",
        "\n",
        "# Com o dataset importado, temos acesso às informações sobre o dataset que vamos trabalhar.\n",
        "# Para exemplificar, vamos utilizar um dataset simples que encontramos no site da UCI\n",
        "url_dados = iris_.metadata.data_url   # contém o endereço da URL dos dados que vamos trabalhar\n",
        "\n",
        "# Mudança dos labels dos atributos do dataset\n",
        "labels_atributos = ['comprimento_sepala', 'largura_sepala', 'comprimento_petala', 'largura_petala', 'classe']\n",
        "\n",
        "# carga do dataset através do csv retirando a linha de labels e colocando os labels definidos por nós (header = 0)\n",
        "iris = pd.read_csv(url_dados, names=labels_atributos, header = 0)\n",
        "\n",
        "#vamos verificar os tipos de cada coluna\n",
        "\n",
        "iris.dtypes\n",
        "iris.head()\n"
      ],
      "metadata": {
        "id": "l5uL-aJlCBBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação dos dados"
      ],
      "metadata": {
        "id": "WbUdOve8DmmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados\n",
        "\n",
        "# Para executarmos os algoritmos para problemas de classificação, precisamos\n",
        "# fazer a separação das bases em treino e teste (holdout)\n",
        "array = iris.values\n",
        "\n",
        "x_atr = array[:,0:4] # atributos\n",
        "y_cls = array[:,4] # classe (target)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_atr, y_cls, test_size=0.20, random_state=7) # fazemos a divisão 20% para teste\n",
        "# e 80% para treino"
      ],
      "metadata": {
        "id": "YMWtLUe-DsYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=7) # faz o particionamento em 3"
      ],
      "metadata": {
        "id": "MuTDaEgAEBC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelagem\n",
        "\n",
        "# Vamos definir uma raíz aleatória que vamos usar nos algoritmos.\n",
        "np.random.seed(7)\n",
        "\n",
        "# Listas para armazenar os modelos, os resultados e os nomes dos modelos\n",
        "modelos = []\n",
        "resultados = []\n",
        "nomes = []\n",
        "\n",
        "# Vamos popular a lista dos modelos\n",
        "modelos.append(('KNN', KNeighborsClassifier()))   # algoritmo KNN\n",
        "modelos.append(('CART', DecisionTreeClassifier())) # algoritmo árvore de decisão\n",
        "modelos.append(('NB', GaussianNB()))               # algoritmo Naive Bayes\n",
        "modelos.append(('SVM', SVC()))             # algoritmo Support Vector Machine\n",
        "modelos.append(('RLOG', LogisticRegression())) # algoritmo de Regressão Logística"
      ],
      "metadata": {
        "id": "mK2uUKg1D6dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execução dos modelos (classificação)"
      ],
      "metadata": {
        "id": "iEyCiSiAEUJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nome, modelo in modelos:\n",
        "  resultados_cv = cross_val_score(modelo, x_train, y_train, cv=kfold, scoring='accuracy') # estamos buscando a acurácia\n",
        "\n",
        "  resultados.append(resultados_cv)\n",
        "  nomes.append(nome)\n",
        "  msg = \"%s: %f (%f)\" % (nome, resultados_cv.mean(), resultados_cv.std()) # média e desvio padrão dos 3 resultados da validação cruzada\n",
        "\n",
        "  print(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq9sQNI5EVJp",
        "outputId": "d10a26c6-29f0-4cd5-e92e-b20c7c2ec753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN: 0.975000 (0.020412)\n",
            "CART: 0.966667 (0.011785)\n",
            "NB: 0.975000 (0.020412)\n",
            "SVM: 0.991667 (0.011785)\n",
            "RLOG: 0.975000 (0.020412)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentro dos parâmetros utilizados, o SVM foi o que apresentou o melhor resultado, como será que o SVM performa se o treinarmos com a base completa de treino?"
      ],
      "metadata": {
        "id": "xBYRT6SDEoYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um modelo com todo o conjunto de treino\n",
        "modelo = SVC()\n",
        "modelo.fit(x_train, y_train)\n",
        "# Fazendo as predições com o conjunto de teste\n",
        "predic = modelo.predict(x_test)\n",
        "# Estimando a acurácia no conjunto de teste\n",
        "print(accuracy_score(y_test, predic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiJlljomEgKX",
        "outputId": "7bd7ba97-afcd-48b0-defb-3f49f498025f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8666666666666667\n"
          ]
        }
      ]
    }
  ]
}